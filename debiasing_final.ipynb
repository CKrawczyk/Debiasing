{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from scipy.stats import binned_statistic, scoreatpercentile\n",
    "import pickle\n",
    "from scipy.optimize import minimize\n",
    "import time\n",
    "from voronoi_2d_binning import voronoi_2d_binning\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import imp # reload modules if necessary\n",
    "\n",
    "import binning\n",
    "import bin_debiasing\n",
    "import fit_debiasing\n",
    "import make_dictionaries\n",
    "import params\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib as mpl\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8)\n",
    "plt.rcParams['font.size'] = 18\n",
    "mpl.ticker.AutoLocator.default_params['nbins'] = 5\n",
    "mpl.ticker.AutoLocator.default_params['prune'] = 'both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('output_files/') if os.path.isdir('output_files/') is False else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source_directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-59abe3de3b7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfull_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_directory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfull_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loaded galaxy data...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'source_directory' is not defined"
     ]
    }
   ],
   "source": [
    "full_data = Table.read(source_directory + full_sample)\n",
    "print('Loaded galaxy data...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions = make_dictionaries.questions\n",
    "print('Loaded questions...')\n",
    "function_dictionary = make_dictionaries.function_dictionary\n",
    "print('Loaded functions...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reduce_sample(full_data,questions,question,p_cut=0.5,N_cut=5,normalised_values=True):\n",
    "    ''' Reduce the sample to p>p_cut galaxies only, \n",
    "        using the precedeing questions'''\n",
    "    \n",
    "    previous_q = questions[question]['pre_questions']\n",
    "    previous_a = questions[question]['pre_answers']\n",
    "    \n",
    "    if normalised_values == True:\n",
    "        suffix = '_debiased_rh_normalised'\n",
    "    else:\n",
    "        suffix = '_debiased_rh'\n",
    "    \n",
    "    if previous_q != None:\n",
    "        \n",
    "        p_col = np.ones(len(full_data))\n",
    "        \n",
    "        for m in range(len(previous_q)):\n",
    "            p_col = p_col*(full_data[previous_q[m] + '_' + previous_a[m] + suffix])\n",
    "        N_col = (full_data[previous_q[-1] + '_' + previous_a[-1]])\n",
    "        \n",
    "        select = (p_col > p_cut) & (N_col >= N_cut)\n",
    "        data_reduced = full_data[select]\n",
    "        print('{}/{} galaxies with p>{} and N>={}.'.format(len(data_reduced),\n",
    "                                                          len(full_data),p_cut,N_cut))\n",
    "    \n",
    "    else:\n",
    "        data_reduced = full_data.copy()\n",
    "        print('Primary question, so all {} galaxies used.'.format(len(data_reduced)))\n",
    "    \n",
    "    return data_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bins(question,answer):\n",
    "    ''' Get bins if they have already been created from a \n",
    "        previous running of the debiasing'''\n",
    "    \n",
    "    bins = Table.read('output_files/'+ question + '/' + answer + '/bins.fits')\n",
    "    all_bins = Table.read('output_files/'+ question + '/' + answer + '/all_bins.fits')\n",
    "    vbins_table = Table.read('output_files/'+ question + '/' + answer + '/vbin_parameters.fits')\n",
    "    \n",
    "    vbins = bins['vbin']\n",
    "    zbins = bins['zbin']\n",
    "    zbins_coarse = bins['coarse_zbin']\n",
    "    vbins_all = all_bins['vbin']\n",
    "    zbins_all = all_bins['zbin']\n",
    "    zbins_coarse_all = all_bins['coarse_zbin']\n",
    "    \n",
    "    return vbins,zbins,zbins_coarse,vbins_all,zbins_all,zbins_coarse_all,vbins_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def histogram_fractions(data,hist_bins):\n",
    "    ''' Get raw histogram values '''\n",
    "    h,bin_edges = np.histogram(data,bins=hist_bins)\n",
    "    f = h/np.sum(h)\n",
    "    return f\n",
    "\n",
    "\n",
    "def bin_by_column(column, nbins, fixedcount=True):\n",
    "    ''' Bin the data into redshift slices \n",
    "    (or by any column) '''\n",
    "    \n",
    "    sorted_indices = np.argsort(column)\n",
    "    if fixedcount:\n",
    "        bin_edges = np.linspace(0, 1, nbins + 1)\n",
    "        bin_edges[-1] += 1\n",
    "        values = np.empty(len(column))\n",
    "        values[sorted_indices] = np.linspace(0, 1, len(column))\n",
    "        bins = np.digitize(values, bins=bin_edges)\n",
    "    else:\n",
    "        bin_edges = np.linspace(np.min(column),np.max(column), nbins + 1)\n",
    "        bin_edges[-1] += 1\n",
    "        values = column\n",
    "        bins = np.digitize(values, bins=bin_edges)\n",
    "    x, b, n = binned_statistic(values, column, bins=bin_edges)\n",
    "    return x, bins\n",
    "\n",
    "\n",
    "def get_rms(dataset,reference,redshifts):\n",
    "    ''' Calculate rms of a dataset in comparison w. reference data'''\n",
    "    hist_bins = np.linspace(0,1,11)\n",
    "    hist_bins[0] = -1\n",
    "    hist_bins[-1] = 2\n",
    "    zv,zb = bin_by_column(redshifts,nbins=10)\n",
    "    \n",
    "    rms_values = np.zeros(len(np.unique(zb)))\n",
    "    ref_fractions = histogram_fractions(reference,hist_bins)\n",
    "    \n",
    "    for i,z in enumerate(np.unique(zb)):\n",
    "        \n",
    "        sample = dataset[zb == z]\n",
    "        fractions = histogram_fractions(sample,hist_bins)\n",
    "        rms_values[i] = np.sum((fractions-ref_fractions)**2)\n",
    "    \n",
    "    return np.sum(rms_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_best_function(raw_data,debiased,question,answer):\n",
    "    ''' Decide on which set of debiasing values is preferred'''\n",
    "    volume_ok = raw_data['in_volume_limit'] == 1\n",
    "    \n",
    "    # Raw data for reference:\n",
    "    vl  = raw_data[volume_ok][question + '_' + answer]\n",
    "    \n",
    "    # 2 sets of debiased data for comparison:\n",
    "    vl_bin = debiased['bin_method'][volume_ok]\n",
    "    vl_fit = debiased['fit_method'][volume_ok]\n",
    "    redshifts = full_data['Z_TONRY'][volume_ok]\n",
    "    \n",
    "    low_z = (redshifts >= 0.03) & (redshifts < 0.035)\n",
    "    reference = vl[low_z] # raw low-z for comparison\n",
    "    \n",
    "    rms_bin = get_rms(vl_bin,reference,redshifts) # get rms values\n",
    "    rms_fit = get_rms(vl_fit,reference,redshifts) # get rms values\n",
    "    \n",
    "    print('rms^2(bin) = {0:.3f}'.format(rms_bin))\n",
    "    print('rms^2(fit) = {0:.3f}'.format(rms_fit))\n",
    "    if rms_bin < rms_fit:\n",
    "        print('---> bin method selected')\n",
    "        debiased_values = debiased['bin_method']\n",
    "    else:\n",
    "        print('---> fit method selected')\n",
    "        debiased_values = debiased['fit_method'] # Prefer fit method if it \n",
    "        # has better rms^2 value.\n",
    "        \n",
    "    return debiased_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bin_and_debias(full_data,question,questions,answer\n",
    "                   ,bins_exist=False,n_per_bin=100,coarse=False):\n",
    "    '''Set to 'coarse' to make the fitting only apply to the 'coarse binning'of 4 redshift bins per \n",
    "    voronoi bin rather than the fully binned data'''\n",
    "    \n",
    "    # Create output file folders:\n",
    "    (os.mkdir('output_files/'+ question) if\n",
    "     os.path.isdir('output_files/'+ question) is False else None)\n",
    "    (os.mkdir('output_files/'+ question + '/' + answer) if\n",
    "     os.path.isdir('output_files/'+ question + '/' + answer) is False else None)\n",
    "    \n",
    "    # Only use the p>0.5 and N>= 5 data for a given question:\n",
    "    data = reduce_sample(full_data,questions,question)\n",
    "    \n",
    "    if bins_exist == True:\n",
    "        (vbins,zbins,zbins_coarse,\n",
    "         vbins_all,zbins_all,zbins_coarse_all,\n",
    "         vbins_table) = get_bins(question,answer)\n",
    "        print('Bins obtained from previous iteration...')\n",
    "        \n",
    "    else:\n",
    "        (vbins,zbins,zbins_coarse,\n",
    "         vbins_all,zbins_all,zbins_coarse_all,\n",
    "         vbins_table) = binning.bin_data(data,full_data,\n",
    "                                        question,answer,\n",
    "                                        signal=n_per_bin)\n",
    "        \n",
    "    # Save the binning data:\n",
    "    bin_table = Table([vbins,zbins,zbins_coarse],names=('vbin','zbin','coarse_zbin'))\n",
    "    all_bin_table = Table([vbins_all,zbins_all,zbins_coarse_all],names=('vbin','zbin','coarse_zbin'))\n",
    "    bin_table.write('output_files/'+ question + '/' + answer + '/bins.fits',overwrite=True)\n",
    "    all_bin_table.write('output_files/'+ question + '/' + answer + '/all_bins.fits',overwrite=True)\n",
    "    vbins_table.write('output_files/'+ question + '/' + answer + '/vbin_parameters.fits',overwrite=True)\n",
    "\n",
    "    # Debias using the discrete bin method 1st:\n",
    "    debiased_bin = bin_debiasing.debias(data,full_data,vbins,zbins,vbins_all,zbins_all,question,answer)\n",
    "    # Now debias using the functional fitting method:\n",
    "    debiased_fit,dout,fit_setup,zbins,fit_vbin_results = fit_debiasing.debias_by_fit(data,full_data,vbins,zbins,\n",
    "                                                                                     zbins_coarse,question,answer,\n",
    "                                                                                     function_dictionary,min_log_fv,\n",
    "                                                                                     coarse=coarse)\n",
    "    volume_ok = data['in_volume_limit'] == 1    \n",
    "    vl_data = full_data[volume_ok]\n",
    "    vl_fit = debiased_fit[volume_ok]\n",
    "    vl_bin = debiased_bin[volume_ok]\n",
    "\n",
    "    debiased_table = Table([debiased_bin,debiased_fit],names=('bin_method','fit_method'))\n",
    "    debiased_table.write('output_files/'+ question + '/' + answer + '/debiased.fits',overwrite=True)\n",
    "    dout.write('output_files/'+ question + '/' + answer + '/fit_results.fits',overwrite=True)\n",
    "    pickle.dump(fit_setup,open('output_files/'+ question + '/' + answer + '/fit_setup.p', \"wb\" ))\n",
    "    \n",
    "    return debiased_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(binning)\n",
    "imp.reload(params)\n",
    "imp.reload(bin_debiasing)\n",
    "imp.reload(fit_debiasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "question_order = ['shape',\n",
    "                  'disk',\n",
    "                  'bar',\n",
    "                  'spiral_a',\n",
    "                  'bulge_a',\n",
    "                  'round',\n",
    "                  'bulge_b',\n",
    "                  'spiral_b',\n",
    "                  'spiral_c']\n",
    "\n",
    "for question in question_order[1:]:\n",
    "    answers = questions[question]['answers']\n",
    "    \n",
    "    for answer in answers:\n",
    "        \n",
    "        #bins_exist = os.path.isfile('output_files/'+ question + '/' + answer + '/bins.fits')\n",
    "        bins_exist = False\n",
    "        \n",
    "        print('----------------------------------')\n",
    "        print('Question to be debiased:',question)\n",
    "        print('Answer to be debiased:',answer)\n",
    "        \n",
    "        debiased = bin_and_debias(full_data,question,questions,answer,\n",
    "                                  bins_exist=bins_exist,n_per_bin=50,coarse=False) # Use smaller bins!\n",
    "        \n",
    "        deb_vals = choose_best_function(full_data,debiased,question,answer)\n",
    "        full_data[question + '_' + answer + '_debiased_rh'] = deb_vals\n",
    "        \n",
    "        print('----------------------------------')\n",
    "\n",
    "    debiased_values = np.array([full_data[question + '_' + a + '_debiased_rh'] for a in answers])\n",
    "    debiased_norm = debiased_values/np.sum(debiased_values,axis=0)\n",
    "    debiased_norm[np.isnan(debiased_norm)] = 0\n",
    "    for m in range(len(debiased_norm)):\n",
    "        full_data[question + '_' + answers[m] + '_debiased_rh_normalised'] = debiased_norm[m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the debiased values to a FITS file, which can be combined in to full sample using Recover_full_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "debiased_columns = []\n",
    "\n",
    "for m in range(len(full_data.colnames)):\n",
    "    c = full_data.colnames[m]\n",
    "    if 'debiased_rh' in c:\n",
    "        debiased_columns.append(c)\n",
    "        \n",
    "debiased_values = full_data[debiased_columns]\n",
    "debiased_values.write(source_directory + 'debiased_values.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,2,figsize=(20,10),sharex=True,sharey=True)\n",
    "fig.subplots_adjust(wspace=0,hspace=0)\n",
    "\n",
    "z = full_data['Z_TONRY']\n",
    "scaled_z = (z - z.min()) / z.ptp()\n",
    "colors = plt.cm.coolwarm(scaled_z)\n",
    "\n",
    "s = axarr[0].scatter(full_data['shape_smooth_fraction'],full_data['shape_smooth_debiased_rh'],\n",
    "                     c=z,lw=0,s=20,cmap=plt.cm.coolwarm)\n",
    "\n",
    "s = axarr[1].scatter(full_data['shape_features_fraction'],full_data['shape_features_debiased_rh'],\n",
    "                     c=z,lw=0,s=20,cmap=plt.cm.coolwarm)\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.825, 0.125, 0.02, 0.775])\n",
    "fig.colorbar(s, cax=cbar_ax,label='redshift')\n",
    "\n",
    "_ = axarr[0].set_xlabel('$p_\\mathrm{smooth, \\, raw}$')\n",
    "_ = axarr[1].set_xlabel('$p_\\mathrm{features, \\, raw}$')\n",
    "_ = axarr[0].set_ylabel('$p_\\mathrm{debiased}$')\n",
    "_ = axarr[0].set_xlim(0,1)\n",
    "_ = axarr[0].set_ylim(0,1)\n",
    "\n",
    "fig.savefig('shape_debiased.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
