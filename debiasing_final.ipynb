{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from scipy.stats import binned_statistic, scoreatpercentile\n",
    "import pickle\n",
    "from scipy.optimize import minimize\n",
    "import time\n",
    "from voronoi_2d_binning import voronoi_2d_binning\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import imp # reload modules if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import binning\n",
    "import bin_debiasing\n",
    "import fit_debiasing\n",
    "import make_dictionaries\n",
    "import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib as mpl\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8)\n",
    "plt.rcParams['font.size'] = 18\n",
    "mpl.ticker.AutoLocator.default_params['nbins'] = 5\n",
    "mpl.ticker.AutoLocator.default_params['prune'] = 'both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('output_files/') if os.path.isdir('output_files/') is False else None\n",
    "\n",
    "source_directory = params.source_directory\n",
    "full_sample = params.full_sample\n",
    "\n",
    "min_log_fv = -1.5\n",
    "max_log_fv = 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded galaxy data...\n"
     ]
    }
   ],
   "source": [
    "full_data = Table.read(source_directory + full_sample)\n",
    "print('Loaded galaxy data...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded questions...\n",
      "Loaded functions...\n"
     ]
    }
   ],
   "source": [
    "questions = make_dictionaries.questions\n",
    "print('Loaded questions...')\n",
    "function_dictionary = make_dictionaries.function_dictionary\n",
    "print('Loaded functions...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'params' from '/Users/rosshart/Desktop/Debiasing/params.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reduce_sample(full_data,questions,question,p_cut=0.5,N_cut=5,normalised_values=True):\n",
    "    ''' Reduce the sample to p>p_cut galaxies only, \n",
    "        using the precedeing questions'''\n",
    "    \n",
    "    previous_q = questions[question]['pre_questions']\n",
    "    previous_a = questions[question]['pre_answers']\n",
    "    \n",
    "    if normalised_values == True:\n",
    "        suffix = '_debiased_rh_normalised'\n",
    "    else:\n",
    "        suffix = '_debiased_rh'\n",
    "    \n",
    "    if previous_q != None:\n",
    "        \n",
    "        p_col = np.ones(len(full_data))\n",
    "        \n",
    "        for m in range(len(previous_q)):\n",
    "            p_col = p_col*(full_data[previous_q[m] + '_' + previous_a[m] + suffix])\n",
    "        N_col = (full_data[previous_q[-1] + '_' + previous_a[-1] + '_count'])\n",
    "        \n",
    "        select = (p_col > p_cut) & (N_col >= N_cut)\n",
    "        data_reduced = full_data[select]\n",
    "        print('{}/{} galaxies with p>{} and N>={}.'.format(len(data_reduced),\n",
    "                                                          len(full_data),p_cut,N_cut))\n",
    "    \n",
    "    else:\n",
    "        data_reduced = full_data.copy()\n",
    "        print('Primary question, so all {} galaxies used.'.format(len(data_reduced)))\n",
    "    \n",
    "    return data_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bins(question,answer):\n",
    "    ''' Get bins if they have already been created from a \n",
    "        previous running of the debiasing'''\n",
    "    \n",
    "    bins = Table.read('output_files/'+ question + '/' + answer + '/bins.fits')\n",
    "    all_bins = Table.read('output_files/'+ question + '/' + answer + '/all_bins.fits')\n",
    "    vbins_table = Table.read('output_files/'+ question + '/' + answer + '/vbin_parameters.fits')\n",
    "    \n",
    "    vbins = bins['vbin']\n",
    "    zbins = bins['zbin']\n",
    "    zbins_coarse = bins['coarse_zbin']\n",
    "    vbins_all = all_bins['vbin']\n",
    "    zbins_all = all_bins['zbin']\n",
    "    zbins_coarse_all = all_bins['coarse_zbin']\n",
    "    \n",
    "    return vbins,zbins,zbins_coarse,vbins_all,zbins_all,zbins_coarse_all,vbins_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def histogram_fractions(data,hist_bins):\n",
    "    ''' Get raw histogram values '''\n",
    "    h,bin_edges = np.histogram(data,bins=hist_bins)\n",
    "    f = h/np.sum(h)\n",
    "    return f\n",
    "\n",
    "\n",
    "def bin_by_column(column, nbins, fixedcount=True):\n",
    "    ''' Bin the data into redshift slices \n",
    "    (or by any column) '''\n",
    "    \n",
    "    sorted_indices = np.argsort(column)\n",
    "    if fixedcount:\n",
    "        bin_edges = np.linspace(0, 1, nbins + 1)\n",
    "        bin_edges[-1] += 1\n",
    "        values = np.empty(len(column))\n",
    "        values[sorted_indices] = np.linspace(0, 1, len(column))\n",
    "        bins = np.digitize(values, bins=bin_edges)\n",
    "    else:\n",
    "        bin_edges = np.linspace(np.min(column),np.max(column), nbins + 1)\n",
    "        bin_edges[-1] += 1\n",
    "        values = column\n",
    "        bins = np.digitize(values, bins=bin_edges)\n",
    "    x, b, n = binned_statistic(values, column, bins=bin_edges)\n",
    "    return x, bins\n",
    "\n",
    "\n",
    "def get_rms(dataset,reference,redshifts):\n",
    "    ''' Calculate rms of a dataset in comparison w. reference data'''\n",
    "    hist_bins = np.linspace(0,1,11)\n",
    "    hist_bins[0] = -1\n",
    "    hist_bins[-1] = 2\n",
    "    zv,zb = bin_by_column(redshifts,nbins=10)\n",
    "    \n",
    "    rms_values = np.zeros(len(np.unique(zb)))\n",
    "    ref_fractions = histogram_fractions(reference,hist_bins)\n",
    "    \n",
    "    for i,z in enumerate(np.unique(zb)):\n",
    "        \n",
    "        sample = dataset[zb == z]\n",
    "        fractions = histogram_fractions(sample,hist_bins)\n",
    "        rms_values[i] = np.sum((fractions-ref_fractions)**2)\n",
    "    \n",
    "    return np.sum(rms_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_best_function(raw_data,debiased,question,answer):\n",
    "    ''' Decide on which set of debiasing values is preferred'''\n",
    "    volume_ok = raw_data['in_volume_limit'] == 1\n",
    "    \n",
    "    # Raw data for reference:\n",
    "    vl  = raw_data[volume_ok][question + '_' + answer]\n",
    "    \n",
    "    # 2 sets of debiased data for comparison:\n",
    "    vl_bin = debiased['bin_method'][volume_ok]\n",
    "    vl_fit = debiased['fit_method'][volume_ok]\n",
    "    redshifts = full_data['REDSHIFT_1'][volume_ok]\n",
    "    \n",
    "    low_z = (redshifts >= 0.03) & (redshifts < 0.035)\n",
    "    reference = vl[low_z] # raw low-z for comparison\n",
    "    \n",
    "    rms_bin = get_rms(vl_bin,reference,redshifts) # get rms values\n",
    "    rms_fit = get_rms(vl_fit,reference,redshifts) # get rms values\n",
    "    \n",
    "    print('rms^2(bin) = {0:.3f}'.format(rms_bin))\n",
    "    print('rms^2(fit) = {0:.3f}'.format(rms_fit))\n",
    "    if rms_bin < rms_fit:\n",
    "        print('---> bin method selected')\n",
    "        debiased_values = debiased['bin_method']\n",
    "    else:\n",
    "        print('---> fit method selected')\n",
    "        debiased_values = debiased['fit_method'] # Prefer fit method if it \n",
    "        # has better rms^2 value.\n",
    "        \n",
    "    return debiased_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bin_and_debias(full_data,question,questions,answer\n",
    "                   ,bins_exist=False,n_per_bin=100,coarse=False):\n",
    "    '''Set to 'coarse' to make the fitting only apply to the 'coarse binning'of 4 redshift bins per \n",
    "    voronoi bin rather than the fully binned data'''\n",
    "    \n",
    "    # Create output file folders:\n",
    "    (os.mkdir('output_files/'+ question) if\n",
    "     os.path.isdir('output_files/'+ question) is False else None)\n",
    "    (os.mkdir('output_files/'+ question + '/' + answer) if\n",
    "     os.path.isdir('output_files/'+ question + '/' + answer) is False else None)\n",
    "    \n",
    "    # Only use the p>0.5 and N>= 5 data for a given question:\n",
    "    data = reduce_sample(full_data,questions,question)\n",
    "    \n",
    "    if bins_exist == True:\n",
    "        (vbins,zbins,zbins_coarse,\n",
    "         vbins_all,zbins_all,zbins_coarse_all,\n",
    "         vbins_table) = get_bins(question,answer)\n",
    "        print('Bins obtained from previous iteration...')\n",
    "        \n",
    "    else:\n",
    "        (vbins,zbins,zbins_coarse,\n",
    "         vbins_all,zbins_all,zbins_coarse_all,\n",
    "         vbins_table) = binning.bin_data(data,full_data,\n",
    "                                        question,answer,\n",
    "                                        signal=n_per_bin)\n",
    "        \n",
    "    # Save the binning data:\n",
    "    bin_table = Table([vbins,zbins,zbins_coarse],names=('vbin','zbin','coarse_zbin'))\n",
    "    all_bin_table = Table([vbins_all,zbins_all,zbins_coarse_all],names=('vbin','zbin','coarse_zbin'))\n",
    "    bin_table.write('output_files/'+ question + '/' + answer + '/bins.fits',overwrite=True)\n",
    "    all_bin_table.write('output_files/'+ question + '/' + answer + '/all_bins.fits',overwrite=True)\n",
    "    vbins_table.write('output_files/'+ question + '/' + answer + '/vbin_parameters.fits',overwrite=True)\n",
    "\n",
    "    # Debias using the discrete bin method 1st:\n",
    "    debiased_bin = bin_debiasing.debias(data,full_data,vbins,zbins,vbins_all,zbins_all,question,answer)\n",
    "    # Now debias using the functional fitting method:\n",
    "    debiased_fit,dout,fit_setup,zbins,fit_vbin_results = fit_debiasing.debias_by_fit(data,full_data,vbins,zbins,\n",
    "                                                                                     zbins_coarse,question,answer,\n",
    "                                                                                     function_dictionary,min_log_fv,\n",
    "                                                                                     coarse=coarse)\n",
    "    \n",
    "    volume_ok = data['in_volume_limit'] == 1    \n",
    "    vl_data = full_data[volume_ok]\n",
    "    vl_fit = debiased_fit[volume_ok]\n",
    "    vl_bin = debiased_bin[volume_ok]\n",
    "\n",
    "    debiased_table = Table([debiased_bin,debiased_fit],names=('bin_method','fit_method'))\n",
    "    debiased_table.write('output_files/'+ question + '/' + answer + '/debiased.fits',overwrite=True)\n",
    "    dout.write('output_files/'+ question + '/' + answer + '/fit_results.fits',overwrite=True)\n",
    "    pickle.dump(fit_setup,open('output_files/'+ question + '/' + answer + '/fit_setup.p', \"wb\" ))\n",
    "    \n",
    "    return debiased_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CATAID',\n",
       " 'RA',\n",
       " 'DEC',\n",
       " 'R_PETRO',\n",
       " 'Z',\n",
       " 'NQ',\n",
       " 'NQ2_FLAG',\n",
       " 'SURVEY_CLASS',\n",
       " 'VIS_CLASS',\n",
       " 'subject_id',\n",
       " 'gama_cataid',\n",
       " 'zooniverse_id',\n",
       " 'shape_total',\n",
       " 'shape_smooth',\n",
       " 'shape_features',\n",
       " 'shape_star_or_artifact',\n",
       " 'disk_total',\n",
       " 'disk_yes',\n",
       " 'disk_no',\n",
       " 'bar_total',\n",
       " 'bar_bar',\n",
       " 'bar_no_bar',\n",
       " 'spiral_a_total',\n",
       " 'spiral_a_spiral',\n",
       " 'spiral_a_no_spiral',\n",
       " 'bulge_a_total',\n",
       " 'bulge_a_no_bulge',\n",
       " 'bulge_a_obvious',\n",
       " 'bulge_a_dominant',\n",
       " 'spiral_b_total',\n",
       " 'spiral_b_tight',\n",
       " 'spiral_b_medium',\n",
       " 'spiral_b_loose',\n",
       " 'spiral_c_total',\n",
       " 'spiral_c_1',\n",
       " 'spiral_c_2',\n",
       " 'spiral_c_3',\n",
       " 'spiral_c_4',\n",
       " 'spiral_c_more_than_4',\n",
       " 'bulge_b_total',\n",
       " 'bulge_b_rounded',\n",
       " 'bulge_b_boxy',\n",
       " 'bulge_b_no_bulge',\n",
       " 'round_total',\n",
       " 'round_completely_round',\n",
       " 'round_in_between',\n",
       " 'round_cigar_shaped',\n",
       " 'mergers_total',\n",
       " 'mergers_merging',\n",
       " 'mergers_tidal_debris',\n",
       " 'mergers_both',\n",
       " 'mergers_neither',\n",
       " 'odd_total',\n",
       " 'odd_none',\n",
       " 'odd_ring',\n",
       " 'odd_lens_or_arc',\n",
       " 'odd_irregular',\n",
       " 'odd_other',\n",
       " 'odd_dust_lane',\n",
       " 'odd_overlapping',\n",
       " 'discuss_total',\n",
       " 'discuss_yes',\n",
       " 'discuss_no',\n",
       " 'shape_smooth_frac',\n",
       " 'shape_features_frac',\n",
       " 'shape_star_or_artifact_frac',\n",
       " 'disk_yes_frac',\n",
       " 'disk_no_frac',\n",
       " 'bar_bar_frac',\n",
       " 'bar_no_bar_frac',\n",
       " 'spiral_a_spiral_frac',\n",
       " 'spiral_a_no_spiral_frac',\n",
       " 'bulge_a_no_bulge_frac',\n",
       " 'bulge_a_obvious_frac',\n",
       " 'bulge_a_dominant_frac',\n",
       " 'spiral_b_tight_frac',\n",
       " 'spiral_b_medium_frac',\n",
       " 'spiral_b_loose_frac',\n",
       " 'spiral_c_1_frac',\n",
       " 'spiral_c_2_frac',\n",
       " 'spiral_c_3_frac',\n",
       " 'spiral_c_4_frac',\n",
       " 'spiral_c_more_than_4_frac',\n",
       " 'bulge_b_rounded_frac',\n",
       " 'bulge_b_boxy_frac',\n",
       " 'bulge_b_no_bulge_frac',\n",
       " 'round_completely_round_frac',\n",
       " 'round_in_between_frac',\n",
       " 'round_cigar_shaped_frac',\n",
       " 'mergers_merging_frac',\n",
       " 'mergers_tidal_debris_frac',\n",
       " 'mergers_both_frac',\n",
       " 'mergers_neither_frac',\n",
       " 'odd_none_frac',\n",
       " 'odd_ring_frac',\n",
       " 'odd_lens_or_arc_frac',\n",
       " 'odd_irregular_frac',\n",
       " 'odd_other_frac',\n",
       " 'odd_dust_lane_frac',\n",
       " 'odd_overlapping_frac',\n",
       " 'discuss_yes_frac',\n",
       " 'discuss_no_frac',\n",
       " 'survey_id',\n",
       " 'zooniverse_id_2']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(binning)\n",
    "\n",
    "full_data.colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Question to be debiased: shape\n",
      "Answer to be debiased: smooth\n",
      "Primary question, so all 11507 galaxies used.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'PETROR50_R_KPC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bd12ba8e745c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         debiased = bin_and_debias(full_data,question,questions,answer,\n\u001b[0;32m---> 24\u001b[0;31m                                   bins_exist=bins_exist,n_per_bin=50,coarse=False) # Use smaller bins!\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdeb_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoose_best_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebiased\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-eb941ddc8e7b>\u001b[0m in \u001b[0;36mbin_and_debias\u001b[0;34m(full_data, question, questions, answer, bins_exist, n_per_bin, coarse)\u001b[0m\n\u001b[1;32m     24\u001b[0m          \u001b[0mvbins_table\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                         \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                         signal=n_per_bin)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Save the binning data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rosshart/Desktop/Debiasing/binning.py\u001b[0m in \u001b[0;36mbin_data\u001b[0;34m(data, full_data, question, answer, n_vbins, signal)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mfv_nonzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_column\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# Select only the non-zero data to add to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# 'signal' for each bin.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mR50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PETROR50_R_KPC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfv_nonzero\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0mMr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PETROMAG_MR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfv_nonzero\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rosshart/anaconda/lib/python3.4/site-packages/astropy/table/table.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rosshart/anaconda/lib/python3.4/site-packages/astropy/table/table.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PETROR50_R_KPC'"
     ]
    }
   ],
   "source": [
    "question_order = ['shape',\n",
    "                  'disk',\n",
    "                  'bar',\n",
    "                  'spiral_a',\n",
    "                  'bulge_a',\n",
    "                  'round',\n",
    "                  'bulge_b',\n",
    "                  'spiral_b',\n",
    "                  'spiral_c']\n",
    "\n",
    "for question in question_order[:1]:\n",
    "    answers = questions[question]['answers']\n",
    "    \n",
    "    for answer in answers:\n",
    "        \n",
    "        #bins_exist = os.path.isfile('output_files/'+ question + '/' + answer + '/bins.fits')\n",
    "        bins_exist = False\n",
    "        \n",
    "        print('----------------------------------')\n",
    "        print('Question to be debiased:',question)\n",
    "        print('Answer to be debiased:',answer)\n",
    "        \n",
    "        debiased = bin_and_debias(full_data,question,questions,answer,\n",
    "                                  bins_exist=bins_exist,n_per_bin=50,coarse=False) # Use smaller bins!\n",
    "        \n",
    "        deb_vals = choose_best_function(full_data,debiased,question,answer)\n",
    "        full_data[question + '_' + answer] = deb_vals\n",
    "        \n",
    "        print('----------------------------------')\n",
    "\n",
    "    debiased_values = np.array([full_data[question + '_' + a + '_debiased_rh'] for a in answers])\n",
    "    debiased_norm = debiased_values/np.sum(debiased_values,axis=0)\n",
    "    debiased_norm[np.isnan(debiased_norm)] = 0\n",
    "    for m in range(len(debiased_norm)):\n",
    "        full_data[question + '_' + answers[m] + '_debiased_rh_normalised'] = debiased_norm[m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the debiased values to a FITS file, which can be combined in to full sample using Recover_full_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "debiased_columns = []\n",
    "\n",
    "for m in range(len(full_data.colnames)):\n",
    "    c = full_data.colnames[m]\n",
    "    if 'debiased_rh' in c:\n",
    "        debiased_columns.append(c)\n",
    "        \n",
    "debiased_values = full_data[debiased_columns]\n",
    "debiased_values.write(source_directory + 'debiased_values.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
